# AtmoTrack: Implementation & Ethics Memo

AtmoTrack is a prototype app I built to explore how AI could help people taking GLP-1 medications by combining symptom tracking with motility data from devices like the Atmo capsule. These medications can be life-changing for weight and metabolic health, but many people stop taking them because of gastrointestinal side effects like nausea, vomiting, bloating, disrupted bowel movements or delayed gastric emptying. My broader capstone project focuses on understanding these side effects using clinically validated motility data, with the goal of improving patient support and helping clinicians make sense of symptom patterns. AtmoTrack gave me a way to translate these ideas into a functional, patient-facing prototype and to test how AI could make symptom tracking and dietary guidance more practical while also showing clinicians useful insights.

I built the prototype entirely in Google AI Studio using Gemini. As I have no computer science or coding background, I didn’t write any of the actual code myself. Instead, I relied on prompts to generate the UI, the interaction logic between tabs, and the behavior of the AI assistant. AI helped create the main sections of the app, including symptom logs, dosing, meal plans, motility insights, and the “About” page. It also generated the initial text for onboarding instructions, symptom labels, disclaimers, and educational explanations about how meals, symptoms, and medication timing interact. While AI provided these drafts, I spent a lot of time editing, refining, and reworking everything to make it clear, practical and appropriate for a healthcare-adjacent context.

My main role was guiding and constraining AI outputs. I had to decide what the AI should and shouldn’t do, simplify overly technical suggestions and make sure the outputs made sense for a patient. For example, the AI sometimes suggested things that could be interpreted as medical advice, so I rewrote those sections to stay educational and supportive without overstepping. Early prompts were broad and produced inconsistent results, but when I made them more detailed and explicit about tone, format, and safety boundaries, the AI became much more reliable.

The core AI feature of AtmoTrack interprets patient-reported symptoms and generates adaptive meal guidance. I chose this because people taking GLP-1 medications often struggle with everyday decisions around eating and appetite, and AI can provide immediate, practical support without making medical decisions. I didn’t include more advanced features like automated dose adjustments or real-time clinical recommendations, because that would require clinical validation, clinician oversight and regulatory involvement. Instead, the prototype demonstrates how symptom logs could be translated into useful advice while leaving actual medical decisions to professionals, who may be aided by the raw data.

Ethical considerations were a major focus while building. Privacy was important, and while the current prototype doesn’t store real patient data, the ultimate goal is to allow symptom logs to be securely stored and shared with clinicians. I also thought about fairness, since the AI is trained on general language models and doesn’t reflect every person’s diet, culture, or health condition. That’s why outputs are framed as general guidance, not personal medical recommendations. I made sure every AI output clearly notes that it comes from AI, and the app encourages patients to check with clinicians if symptoms persist or worsen. I also reviewed and edited all AI-generated content, so the AI acted as a collaborator rather than a replacement for human judgment.

Working with AI Studio taught me a lot about how AI can be used responsibly. I learned that the quality of outputs depends heavily on the clarity of prompts, and that giving AI detailed instructions about tone, limits, and content improves the results dramatically. I also realized that AI is most useful when it helps translate complex information into something understandable and actionable. It can speed up prototyping and idea testing, even for someone like me without a formal coding background, while still keeping the human in control of key decisions.

This project also shaped how I think about AI in healthcare. I don’t see it as a replacement for human expertise, but as a tool that can help patients and clinicians understand data more easily. Even a simple prototype like AtmoTrack can improve patient engagement and help people feel more informed about their symptoms. In addition it encourages more frequent logging of daily activity which then gives clinicians a clearer picture of trends. The experience taught me valuable lessons about prompt design and how many steps must be taken in the prompting to minimize risk of harm in the output. It massively improves my perspective, however, on the potential of AI to turn complicated biomedical data into usable guidance.

In the end, AtmoTrack is an early but thoughtful exploration of AI in patient-centered care. It focuses on guidance and education while making sure the AI doesn’t overstep ethical or technical limits. The project has shown me how AI can be a responsible partner in healthcare prototypes and given me insights I will carry into my capstone and any future projects using AI in health technology.

